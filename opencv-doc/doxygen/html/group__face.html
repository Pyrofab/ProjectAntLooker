<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>JavaCV: Face Recognition</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">JavaCV
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Face Recognition</div>  </div>
</div><!--header-->
<div class="contents">

<p>Abstract base class for all strategies of prediction result handling.  
<a href="#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.PredictCollector</b></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.StandardCollector</b></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default predict collector. <br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.FaceRecognizer</b></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.BasicFaceRecognizer</b></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.LBPHFaceRecognizer</b></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga6f3a56396530d46af3fba9ad04fc80cf"><td class="memItemLeft" align="right" valign="top">static native BasicFaceRecognizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__face.html#ga6f3a56396530d46af3fba9ad04fc80cf">org.bytedeco.javacpp.opencv_face.createEigenFaceRecognizer</a> (int num_components, double fr.antproject.utils.threshold)</td></tr>
<tr class="separator:ga6f3a56396530d46af3fba9ad04fc80cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac70e2c94b7d6f05d26f762bed96b2da7"><td class="memItemLeft" align="right" valign="top"><a id="gac70e2c94b7d6f05d26f762bed96b2da7"></a>
static native BasicFaceRecognizer&#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.createEigenFaceRecognizer</b> ()</td></tr>
<tr class="separator:gac70e2c94b7d6f05d26f762bed96b2da7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga80a98f353dd2ef661444e0d79bbe9daf"><td class="memItemLeft" align="right" valign="top">static native BasicFaceRecognizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__face.html#ga80a98f353dd2ef661444e0d79bbe9daf">org.bytedeco.javacpp.opencv_face.createFisherFaceRecognizer</a> (int num_components, double fr.antproject.utils.threshold)</td></tr>
<tr class="separator:ga80a98f353dd2ef661444e0d79bbe9daf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga241cb766e32721cf0ba5c6fde7006808"><td class="memItemLeft" align="right" valign="top"><a id="ga241cb766e32721cf0ba5c6fde7006808"></a>
static native BasicFaceRecognizer&#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.createFisherFaceRecognizer</b> ()</td></tr>
<tr class="separator:ga241cb766e32721cf0ba5c6fde7006808"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga970c161034e055fb56615aadba87ac4e"><td class="memItemLeft" align="right" valign="top">static native LBPHFaceRecognizer&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__face.html#ga970c161034e055fb56615aadba87ac4e">org.bytedeco.javacpp.opencv_face.createLBPHFaceRecognizer</a> (int radius, int neighbors, int grid_x, int grid_y, double fr.antproject.utils.threshold)</td></tr>
<tr class="separator:ga970c161034e055fb56615aadba87ac4e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6d5f6361f7aeeb413b5e582ac60ae6e5"><td class="memItemLeft" align="right" valign="top"><a id="ga6d5f6361f7aeeb413b5e582ac60ae6e5"></a>
static native LBPHFaceRecognizer&#160;</td><td class="memItemRight" valign="bottom"><b>org.bytedeco.javacpp.opencv_face.createLBPHFaceRecognizer</b> ()</td></tr>
<tr class="separator:ga6d5f6361f7aeeb413b5e582ac60ae6e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>Abstract base class for all strategies of prediction result handling. </p>
<p>Abstract base class for all face recognition models.</p>
<ul>
<li>face_changelog</li>
<li>tutorial_face_main </li>
</ul>
<p>/**</p>
<p>/**</p>
<p>All face recognition models in OpenCV are derived from the abstract base class FaceRecognizer, which provides a unified access to all face recongition algorithms in OpenCV. </p>
<h3>Description</h3>
<p>I'll go a bit more into detail explaining FaceRecognizer, because it doesn't look like a powerful interface at first sight. But: Every FaceRecognizer is an Algorithm, so you can easily get/set all model internals (if allowed by the implementation). Algorithm is a relatively new OpenCV concept, which is available since the 2.4 release. I suggest you take a look at its description. </p>
<p>Algorithm provides the following features for all derived classes: </p>
<ul>
<li>So called “virtual constructor”. That is, each Algorithm derivative is registered at program start and you can get the list of registered algorithms and create instance of a particular algorithm by its name (see Algorithm::create). If you plan to add your own algorithms, it is good practice to add a unique prefix to your algorithms to distinguish them from other algorithms.</li>
<li>Setting/Retrieving algorithm parameters by name. If you used video capturing functionality from OpenCV highgui module, you are probably familar with cv::cvSetCaptureProperty, ocvcvGetCaptureProperty, VideoCapture::set and VideoCapture::get. Algorithm provides similar method where instead of integer id's you specify the parameter names as text Strings. See Algorithm::set and Algorithm::get for details.</li>
<li>Reading and writing parameters from/to XML or YAML files. Every Algorithm derivative can store all its parameters and then read them back. There is no need to re-implement it each time. </li>
</ul>
<p>Moreover every FaceRecognizer supports the: </p>
<ul>
<li><b>Training</b> of a FaceRecognizer with FaceRecognizer::train on a given set of images (your face database!).</li>
<li><b>Prediction</b> of a given sample image, that means a face. The image is given as a Mat.</li>
<li><b>Loading/Saving</b> the model state from/to a given XML or YAML.</li>
<li><b>Setting/Getting labels info</b>, that is stored as a string. String labels info is useful for keeping names of the recognized people. </li>
</ul>
<dl class="section note"><dt>Note</dt><dd>When using the FaceRecognizer interface in combination with Python, please stick to Python 2. Some underlying scripts like create_csv will not work in other versions, like Python 3. Setting the Thresholds +++++++++++++++++++++++ </dd></dl>
<p>Sometimes you run into the situation, when you want to apply a fr.antproject.utils.threshold on the prediction. A common scenario in face recognition is to tell, whether a face belongs to the training dataset or if it is unknown. You might wonder, why there's no public API in FaceRecognizer to set the fr.antproject.utils.threshold for the prediction, but rest assured: It's supported. It just means there's no generic way in an abstract class to provide an interface for setting/getting the thresholds of <em>every possible</em> FaceRecognizer algorithm. The appropriate place to set the thresholds is in the constructor of the specific FaceRecognizer and since every FaceRecognizer is a Algorithm (see above), you can get/set the thresholds at runtime! </p>
<p>Here is an example of setting a fr.antproject.utils.threshold for the Eigenfaces method, when creating the model: </p>
<pre><div class="fragment"><div class="line"><span class="comment">// Let&#39;s say we want to keep 10 Eigenfaces and have a fr.antproject.utils.threshold value of 10.0</span></div><div class="line"><span class="keywordtype">int</span> num_components = 10;</div><div class="line"><span class="keywordtype">double</span> fr.antproject.utils.threshold = 10.0;</div><div class="line"><span class="comment">// Then if you want to have a cv::FaceRecognizer with a confidence fr.antproject.utils.threshold,</span></div><div class="line"><span class="comment">// create the concrete implementation with the appropiate parameters:</span></div><div class="line">Ptr&lt;FaceRecognizer&gt; model = <a class="code" href="group__face.html#ga6f3a56396530d46af3fba9ad04fc80cf">createEigenFaceRecognizer</a>(num_components, fr.antproject.utils.threshold);</div></div><!-- fragment --> </pre> <p>Sometimes it's impossible to train the model, just to experiment with fr.antproject.utils.threshold values. Thanks to Algorithm it's possible to set internal model thresholds during runtime. Let's see how we would set/get the prediction for the Eigenface model, we've created above: </p>
<pre><div class="fragment"><div class="line"><span class="comment">// The following line reads the fr.antproject.utils.threshold from the Eigenfaces model:</span></div><div class="line"><span class="keywordtype">double</span> current_threshold = model-&gt;getDouble(<span class="stringliteral">&quot;fr.antproject.utils.threshold&quot;</span>);</div><div class="line"><span class="comment">// And this line sets the fr.antproject.utils.threshold to 0.0:</span></div><div class="line">model-&gt;set(<span class="stringliteral">&quot;fr.antproject.utils.threshold&quot;</span>, 0.0);</div></div><!-- fragment --> </pre> <p>If you've set the fr.antproject.utils.threshold to 0.0 as we did above, then: </p>
<pre><div class="fragment"><div class="line"><span class="comment">//</span></div><div class="line">Mat img = imread(<span class="stringliteral">&quot;person1/3.jpg&quot;</span>, CV_LOAD_IMAGE_GRAYSCALE);</div><div class="line"><span class="comment">// Get a prediction from the model. Note: We&#39;ve set a fr.antproject.utils.threshold of 0.0 above,</span></div><div class="line"><span class="comment">// since the distance is almost always larger than 0.0, you&#39;ll get -1 as</span></div><div class="line"><span class="comment">// label, which indicates, this face is unknown</span></div><div class="line"><span class="keywordtype">int</span> predicted_label = model-&gt;predict(img);</div><div class="line"><span class="comment">// ...</span></div></div><!-- fragment --> </pre> <p>is going to yield -1 as predicted label, which states this face is unknown. </p>
<h3>Getting the name of a FaceRecognizer</h3>
<p>Since every FaceRecognizer is a Algorithm, you can use Algorithm::name to get the name of a FaceRecognizer: </p>
<pre><div class="fragment"><div class="line"><span class="comment">// Create a FaceRecognizer:</span></div><div class="line">Ptr&lt;FaceRecognizer&gt; model = <a class="code" href="group__face.html#ga6f3a56396530d46af3fba9ad04fc80cf">createEigenFaceRecognizer</a>();</div><div class="line"><span class="comment">// And here&#39;s how to get its name:</span></div><div class="line">String name = model-&gt;name();</div></div><!-- fragment --> </pre> <h2 class="groupheader">Function Documentation</h2>
<a id="ga6f3a56396530d46af3fba9ad04fc80cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6f3a56396530d46af3fba9ad04fc80cf">&#9670;&nbsp;</a></span>createEigenFaceRecognizer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static native BasicFaceRecognizer org.bytedeco.javacpp.opencv_face.createEigenFaceRecognizer </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_components</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>fr.antproject.utils.threshold</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">num_components</td><td>The number of components (read: Eigenfaces) kept for this Principal Component Analysis. As a hint: There's no rule how many components (read: Eigenfaces) should be kept for good reconstruction capabilities. It is based on your input data, so experiment with the number. Keeping 80 components should almost always be sufficient. </td></tr>
    <tr><td class="paramname">fr.antproject.utils.threshold</td><td>The fr.antproject.utils.threshold applied in the prediction. </td></tr>
  </table>
  </dd>
</dl>
<h3>Notes:</h3>
<ul>
<li>Training and prediction must be done on grayscale images, use cvtColor to convert between the color spaces.</li>
<li><b>THE EIGENFACES METHOD MAKES THE ASSUMPTION, THAT THE TRAINING AND TEST IMAGES ARE OF EQUAL SIZE.</b> (caps-lock, because I got so many mails asking for this). You have to make sure your input data has the correct shape, else a meaningful exception is thrown. Use resize to resize the images.</li>
<li>This model does not support updating. </li>
</ul>
<h3>Model internal data:</h3>
<ul>
<li>num_components see createEigenFaceRecognizer.</li>
<li>fr.antproject.utils.threshold see createEigenFaceRecognizer.</li>
<li>eigenvalues The eigenvalues for this Principal Component Analysis (ordered descending).</li>
<li>eigenvectors The eigenvectors for this Principal Component Analysis (ordered by their eigenvalue).</li>
<li>mean The sample mean calculated from the training data.</li>
<li>projections The projections of the training data.</li>
<li>labels The fr.antproject.utils.threshold applied in the prediction. If the distance to the nearest neighbor is larger than the fr.antproject.utils.threshold, this method returns -1. </li>
</ul>

</div>
</div>
<a id="ga80a98f353dd2ef661444e0d79bbe9daf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga80a98f353dd2ef661444e0d79bbe9daf">&#9670;&nbsp;</a></span>createFisherFaceRecognizer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static native BasicFaceRecognizer org.bytedeco.javacpp.opencv_face.createFisherFaceRecognizer </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_components</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>fr.antproject.utils.threshold</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">num_components</td><td>The number of components (read: Fisherfaces) kept for this Linear Discriminant Analysis with the Fisherfaces criterion. It's useful to keep all components, that means the number of your classes c (read: subjects, persons you want to recognize). If you leave this at the default (0) or set it to a value less-equal 0 or greater (c-1), it will be set to the correct number (c-1) automatically. </td></tr>
    <tr><td class="paramname">fr.antproject.utils.threshold</td><td>The fr.antproject.utils.threshold applied in the prediction. If the distance to the nearest neighbor is larger than the fr.antproject.utils.threshold, this method returns -1. </td></tr>
  </table>
  </dd>
</dl>
<h3>Notes:</h3>
<ul>
<li>Training and prediction must be done on grayscale images, use cvtColor to convert between the color spaces.</li>
<li><b>THE FISHERFACES METHOD MAKES THE ASSUMPTION, THAT THE TRAINING AND TEST IMAGES ARE OF EQUAL SIZE.</b> (caps-lock, because I got so many mails asking for this). You have to make sure your input data has the correct shape, else a meaningful exception is thrown. Use resize to resize the images.</li>
<li>This model does not support updating. </li>
</ul>
<h3>Model internal data:</h3>
<ul>
<li>num_components see createFisherFaceRecognizer.</li>
<li>fr.antproject.utils.threshold see createFisherFaceRecognizer.</li>
<li>eigenvalues The eigenvalues for this Linear Discriminant Analysis (ordered descending).</li>
<li>eigenvectors The eigenvectors for this Linear Discriminant Analysis (ordered by their eigenvalue).</li>
<li>mean The sample mean calculated from the training data.</li>
<li>projections The projections of the training data.</li>
<li>labels The labels corresponding to the projections. </li>
</ul>

</div>
</div>
<a id="ga970c161034e055fb56615aadba87ac4e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga970c161034e055fb56615aadba87ac4e">&#9670;&nbsp;</a></span>createLBPHFaceRecognizer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static native LBPHFaceRecognizer org.bytedeco.javacpp.opencv_face.createLBPHFaceRecognizer </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>radius</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>neighbors</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>grid_x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>grid_y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>fr.antproject.utils.threshold</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">radius</td><td>The radius used for building the Circular Local Binary Pattern. The greater the radius, the </td></tr>
    <tr><td class="paramname">neighbors</td><td>The number of sample points to build a Circular Local Binary Pattern from. An appropriate value is to use<div class="fragment"><div class="line">8 </div></div><!-- fragment --> sample points. Keep in mind: the more sample points you include, the higher the computational cost. </td></tr>
    <tr><td class="paramname">grid_x</td><td>The number of cells in the horizontal direction, 8 is a common value used in publications. The more cells, the finer the grid, the higher the dimensionality of the resulting feature vector. </td></tr>
    <tr><td class="paramname">grid_y</td><td>The number of cells in the vertical direction, 8 is a common value used in publications. The more cells, the finer the grid, the higher the dimensionality of the resulting feature vector. </td></tr>
    <tr><td class="paramname">fr.antproject.utils.threshold</td><td>The fr.antproject.utils.threshold applied in the prediction. If the distance to the nearest neighbor is larger than the fr.antproject.utils.threshold, this method returns -1. </td></tr>
  </table>
  </dd>
</dl>
<h3>Notes:</h3>
<ul>
<li>The Circular Local Binary Patterns (used in training and prediction) expect the data given as grayscale images, use cvtColor to convert between the color spaces.</li>
<li>This model supports updating. </li>
</ul>
<h3>Model internal data:</h3>
<ul>
<li>radius see createLBPHFaceRecognizer.</li>
<li>neighbors see createLBPHFaceRecognizer.</li>
<li>grid_x see createLBPHFaceRecognizer.</li>
<li>grid_y see createLBPHFaceRecognizer.</li>
<li>fr.antproject.utils.threshold see createLBPHFaceRecognizer.</li>
<li>histograms Local Binary Patterns Histograms calculated from the given training data (empty if none was given).</li>
<li>labels Labels corresponding to the calculated Local Binary Patterns Histograms. </li>
</ul>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
